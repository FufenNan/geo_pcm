07/31/2024 16:25:05 - INFO - __main__ - ***** Running training *****
07/31/2024 16:25:05 - INFO - __main__ -   Num batches each epoch = 376
07/31/2024 16:25:05 - INFO - __main__ -   Num Epochs = 27
07/31/2024 16:25:05 - INFO - __main__ -   Instantaneous batch size per device = 10
07/31/2024 16:25:05 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 30
07/31/2024 16:25:05 - INFO - __main__ -   Gradient Accumulation steps = 1
07/31/2024 16:25:05 - INFO - __main__ -   Total optimization steps = 10000
Steps:   0%|                                                          | 0/10000 [00:00<?, ?it/s]


Steps:   0%|                      | 1/10000 [13:45<2292:56:05, 825.54s/it, d_loss=2.03, lr=5e-6]Traceback (most recent call last):
  File "/home/haoyum3/.vscode-server/extensions/ms-python.debugpy-2024.8.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/pydevd.py", line 3489, in <module>
    main()
  File "/home/haoyum3/.vscode-server/extensions/ms-python.debugpy-2024.8.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/pydevd.py", line 3482, in main
    globals = debugger.run(setup['file'], None, None, is_module)
  File "/home/haoyum3/.vscode-server/extensions/ms-python.debugpy-2024.8.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/pydevd.py", line 2510, in run
    return self._exec(is_module, entry_point_fn, module_name, file, globals, locals)
  File "/home/haoyum3/.vscode-server/extensions/ms-python.debugpy-2024.8.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/pydevd.py", line 2517, in _exec
    globals = pydevd_runpy.run_path(file, globals, '__main__')
  File "/home/haoyum3/.vscode-server/extensions/ms-python.debugpy-2024.8.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 321, in run_path
    return _run_module_code(code, init_globals, run_name,
  File "/home/haoyum3/.vscode-server/extensions/ms-python.debugpy-2024.8.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 135, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File "/home/haoyum3/.vscode-server/extensions/ms-python.debugpy-2024.8.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py", line 124, in _run_code
    exec(code, run_globals)
  File "train_pcm_lora_sd2_adv.py", line 1538, in <module>
    args = parse_args()
  File "train_pcm_lora_sd2_adv.py", line 1423, in main
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1523, in forward
    else self._run_ddp_forward(*inputs, **kwargs)
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1359, in _run_ddp_forward
    return self.module(*inputs, **kwargs)  # type: ignore[index]
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/accelerate/utils/operations.py", line 817, in forward
    return model_forward(*args, **kwargs)
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/accelerate/utils/operations.py", line 805, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/amp/autocast_mode.py", line 16, in decorate_autocast
    return func(*args, **kwargs)
  File "/home/haoyum3/PCM/Phased-Consistency-Model/code/text_to_image_sd2/discriminator_sd2.py", line 408, in forward
    return self.g_loss(*args)
  File "/home/haoyum3/PCM/Phased-Consistency-Model/code/text_to_image_sd2/discriminator_sd2.py", line 429, in g_loss
    fake_outputs = self._forward(sample_fake, timestep, encoder_hidden_states)
  File "/home/haoyum3/PCM/Phased-Consistency-Model/code/text_to_image_sd2/discriminator_sd2.py", line 401, in _forward
    outputs.append(h(feature))
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/haoyum3/PCM/Phased-Consistency-Model/code/text_to_image_sd2/discriminator_sd2.py", line 366, in forward
    x = self.conv2(x) + x
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/modules/normalization.py", line 287, in forward
    return F.group_norm(
  File "/home/haoyum3/anaconda3/envs/pcm/lib/python3.9/site-packages/torch/nn/functional.py", line 2561, in group_norm
    return torch.group_norm(input, num_groups, weight, bias, eps, torch.backends.cudnn.enabled)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 47.54 GiB of which 50.81 MiB is free. Process 3780444 has 17.70 GiB memory in use. Including non-PyTorch memory, this process has 29.77 GiB memory in use. Of the allocated memory 29.20 GiB is allocated by PyTorch, and 109.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)